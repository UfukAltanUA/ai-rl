{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Game Parameters\n",
    "\n",
    "FPS = 60\n",
    "WINDOW_WIDTH = 400\n",
    "WINDOW_HEIGHT = 420\n",
    "GAME_HEIGHT = 400\n",
    "\n",
    "PADDLE_WIDTH = 15\n",
    "PADDLE_HEIGHT = 60\n",
    "PADDLE_BUFFER = 15\n",
    "\n",
    "BALL_WIDTH = 20\n",
    "BALL_HEIGHT = 20\n",
    "\n",
    "PADDLE_SPEED = 3\n",
    "BALL_X_SPEED = 2\n",
    "BALL_Y_SPEED = 2\n",
    "\n",
    "WHITE = (255,255,255)\n",
    "BLACK = (0,0,0)\n",
    "\n",
    "screen = pygame.display.set_mode((WINDOW_WIDTH, WINDOW_HEIGHT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPaddle(switch, paddleYPos):\n",
    "    \n",
    "    if switch == \"left\":\n",
    "        paddle = pygame.Rect(PADDLE_BUFFER, paddleYPos, PADDLE_WIDTH, PADDLE_HEIGHT)\n",
    "    elif switch == \"right\":\n",
    "        paddle = pygame.Rect(WINDOW_WIDTH - PADDLE_BUFFER - PADDLE_WIDTH, paddleYPos, PADDLE_WIDTH, PADDLE_HEIGHT)\n",
    "        \n",
    "    pygame.draw.rect(screen, WHITE, paddle)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBall(ballXPos, ballYPos):\n",
    "    \n",
    "    ball = pygame.Rect(ballXPos, ballYPos, BALL_WIDTH, BALL_HEIGHT)\n",
    "    \n",
    "    pygame.draw.rect(screen, WHITE, ball)\n",
    "    \n",
    "\n",
    "def updatePaddle(switch, action, paddleYPos, ballYPos):\n",
    "    dft = 7.5 \n",
    "    \n",
    "    # AGENT\n",
    "    if switch == \"left\":\n",
    "        if action == 1:\n",
    "            paddleYPos = paddleYPos - PADDLE_SPEED*dft\n",
    "        if action == 2:\n",
    "            paddleYPos = paddleYPos + PADDLE_SPEED*dft\n",
    "            \n",
    "        if paddleYPos < 0:\n",
    "            paddleYPos = 0\n",
    "        if paddleYPos > GAME_HEIGHT - PADDLE_HEIGHT:\n",
    "            paddleYPos = GAME_HEIGHT - PADDLE_HEIGHT\n",
    "    elif switch == \"right\":\n",
    "        if paddleYPos + PADDLE_HEIGHT/2 < ballYPos + BALL_HEIGHT/2:\n",
    "            paddleYPos = paddleYPos + PADDLE_SPEED*dft\n",
    "        if paddleYPos + PADDLE_HEIGHT/2 > ballYPos + BALL_HEIGHT/2:\n",
    "            paddleYPos = paddleYPos - PADDLE_SPEED*dft   \n",
    "            \n",
    "        if paddleYPos < 0:\n",
    "            paddleYPos = 0\n",
    "        if paddleYPos > GAME_HEIGHT - PADDLE_HEIGHT:\n",
    "            paddleYPos = GAME_HEIGHT - PADDLE_HEIGHT\n",
    "    \n",
    "    return paddleYPos\n",
    "\n",
    "def updateBall(paddle1YPos, paddle2YPos, ballXPos, ballYPos, ballXDirection, ballYDirection,DeltaFrameTime):\n",
    "    \n",
    "    dft = 7.5\n",
    "    \n",
    "    ballXPos = ballXPos + ballXDirection*BALL_X_SPEED*dft\n",
    "    ballYPos = ballYPos + ballYDirection*BALL_Y_SPEED*dft\n",
    "    \n",
    "    score = -0.05\n",
    "    \n",
    "    # agent\n",
    "    if (ballXPos <= (PADDLE_BUFFER + PADDLE_WIDTH)) and ((ballYPos + BALL_HEIGHT) >= paddle1YPos) and (ballYPos <= (paddle1YPos + PADDLE_HEIGHT)) and (ballXDirection == -1):\n",
    "        \n",
    "        ballXDirection = 1 \n",
    "        \n",
    "        score = 10\n",
    "        \n",
    "    elif (ballXPos <= 0):\n",
    "        \n",
    "        ballXDirection = 1\n",
    "        \n",
    "        score = -10 \n",
    "        \n",
    "        return [score, ballXPos ,ballYPos ,ballXDirection, ballYDirection]\n",
    "    \n",
    "    if ((ballXPos >= (WINDOW_WIDTH - PADDLE_WIDTH - PADDLE_BUFFER)) and ((ballYPos + BALL_HEIGHT)>= paddle2YPos) and (ballYPos <= (paddle2YPos + PADDLE_HEIGHT)) and (ballXDirection == 1)):\n",
    "        \n",
    "        ballXDirection = -1\n",
    "    \n",
    "    elif(ballXPos >= WINDOW_WIDTH - BALL_WIDTH):\n",
    "        \n",
    "        ballXDirection = -1\n",
    "        \n",
    "        return [score, ballXPos,ballYPos, ballXDirection, ballYDirection]\n",
    "    \n",
    "    if ballYPos <= 0:\n",
    "        \n",
    "        ballYPos = 0\n",
    "        \n",
    "        ballYDirection = 1\n",
    "        \n",
    "    elif ballYPos >= GAME_HEIGHT - BALL_HEIGHT:\n",
    "        \n",
    "        ballYPos = GAME_HEIGHT - BALL_HEIGHT\n",
    "        \n",
    "        ballYDirection = -1\n",
    "        \n",
    "    return [score, ballXPos,ballYPos,ballXDirection,ballYDirection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment Design\n",
    "\n",
    "class PongGame:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pygame.init()\n",
    "        pygame.display.set_caption(\"Pong DCQL Env\")\n",
    "        \n",
    "        self.paddle1YPos = GAME_HEIGHT/2 - PADDLE_HEIGHT/2\n",
    "        self.paddle2YPos = GAME_HEIGHT/2 - PADDLE_HEIGHT/2\n",
    "        \n",
    "        self.ballXPos = WINDOW_WIDTH/2\n",
    "        \n",
    "        self.clock = pygame.time.Clock()\n",
    "        \n",
    "        self.GScore = 0.0\n",
    "        \n",
    "        self.ballXDirection = random.sample([-1,1],1)[0]\n",
    "        self.ballYDirection = random.sample([-1,1],1)[0]\n",
    "        \n",
    "        self.ballYPos = random.randint(0,9)*(WINDOW_HEIGHT - BALL_HEIGHT)/9\n",
    "        \n",
    "        \n",
    "    def InitialDisplay(self):\n",
    "        \n",
    "        pygame.event.pump()\n",
    "        \n",
    "        screen.fill(BLACK)\n",
    "        \n",
    "        drawPaddle(\"left\", self.paddle1YPos)\n",
    "        drawPaddle(\"right\",self.paddle2YPos)\n",
    "        \n",
    "        drawBall(self.ballXPos, self.ballYPos)\n",
    "        \n",
    "        pygame.display.flip()\n",
    "    \n",
    "    def PlayNextMove(self, action):\n",
    "        \n",
    "        DeltaFrameTime = self.clock.tick(FPS)\n",
    "        \n",
    "        pygame.event.pump()\n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        screen.fill(BLACK)\n",
    "        \n",
    "        self.paddle1YPos = updatePaddle(\"left\", action, self.paddle1YPos, self.ballYPos)\n",
    "        drawPaddle(\"left\", self.paddle1YPos)\n",
    "\n",
    "        self.paddle2YPos = updatePaddle(\"right\", action, self.paddle2YPos, self.ballYPos)\n",
    "        drawPaddle(\"right\", self.paddle2YPos)\n",
    "        \n",
    "        [score, self.ballXPos, self.ballYPos, self.ballXDirection, self.ballYDirection] = updateBall(self.paddle1YPos, self.paddle2YPos, self.ballXPos, self.ballYPos, self.ballXDirection, self.ballYDirection,DeltaFrameTime)\n",
    "        \n",
    "        drawBall(self.ballXPos, self.ballYPos)\n",
    "        \n",
    "        if ( score > 0.5 or score < -0.5):\n",
    "            self.GScore = self.GScore*0.9 + 0.1*score \n",
    "            \n",
    "        ScreenImage = pygame.surfarray.array3d(pygame.display.get_surface())\n",
    "        \n",
    "        pygame.display.flip()\n",
    "        \n",
    "        return [score, ScreenImage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Activation\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constant Variables\n",
    "NBACTIONS = 3\n",
    "IMGHEIGHT = 40\n",
    "IMGWIDTH = 40\n",
    "IMGHISTORY = 4\n",
    "\n",
    "OBSERVEPERIOD = 2000 #2500 tekrardan sonra training başlayacak. Önce Observe.Number of Training Steps   ???????????\n",
    "GAMMA = 0.975\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "ExpReplay_CAPACITY = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.model = self.createModel()\n",
    "        self.ExpReplay = deque()\n",
    "        self.steps = 0\n",
    "        self.epsilon = 1.0    \n",
    "    \n",
    "    def createModel(self):  #Neural Network\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size = 4, strides = (2,2), input_shape = (IMGHEIGHT,IMGWIDTH, IMGHISTORY), padding ='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Conv2D(64, kernel_size = 4, strides = (2,2), padding ='same'))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size = 3, strides = (1,1), padding ='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        model.add(Dense(units= NBACTIONS, activation=\"linear\"))\n",
    "        \n",
    "        model.compile(loss = \"mse\", optimizer=\"adam\")\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    def FindBestAct(self, s): #Will return the action to take\n",
    "        \n",
    "        if random.random() <self.epsilon or self.steps < OBSERVEPERIOD:\n",
    "            return random.randint(0, NBACTIONS-1)\n",
    "        else:\n",
    "            qvalue = self.model.predict(s)\n",
    "            bestA = np.argmax(qvalue)\n",
    "            return bestA\n",
    "        \n",
    "    \n",
    "    \n",
    "    def CaptureSample(self, sample): #Experience replay + Update Epsilon Greedy\n",
    "        \n",
    "        self.ExpReplay.append(sample)\n",
    "        if len(self.ExpReplay) > ExpReplay_CAPACITY:\n",
    "            self.ExpReplay.popleft() #Eski tecrübeleri atmaya başla.\n",
    "            \n",
    "        self.steps += 1\n",
    "        \n",
    "        self.epsilon = 1.0\n",
    "    \n",
    "        if self.steps > OBSERVEPERIOD:\n",
    "            self.epsilon = 0.75\n",
    "            if self.steps > 7000:\n",
    "                self.epsilon = 0.5\n",
    "            if self.steps > 14000:\n",
    "                self.epsilon = 0.25\n",
    "            if self.steps > 30000:\n",
    "                self.epsilon = 0.15\n",
    "            if self.steps > 45000:\n",
    "                self.epsilon = 0.1\n",
    "            if self.steps > 70000:\n",
    "                self.epsilon = 0.05  #Decrease the epsilon greedy by hand (instead of using a decay rate)\n",
    "    \n",
    "    def Process(self):\n",
    "        \n",
    "        if self.steps > OBSERVEPERIOD:\n",
    "            minibatch = random.sample(self.ExpReplay, BATCH_SIZE)\n",
    "            batchlen = len(minibatch)\n",
    "            \n",
    "            inputs = np.zeros((BATCH_SIZE,IMGHEIGHT,IMGWIDTH,IMGHISTORY))\n",
    "            targets = np.zeros((inputs.shape[0],NBACTIONS))\n",
    "            \n",
    "            Q_sa = 0\n",
    "            \n",
    "            for i in range(batchlen):\n",
    "                state_t = minibatch[i][0]\n",
    "                action_t = minibatch[i][1]\n",
    "                reward_t = minibatch[i][2]\n",
    "                state_t1 = minibatch[i][3]\n",
    "                \n",
    "                inputs[i:i + 1] = state_t\n",
    "                targets[i]  = self.model.predict(state_t)\n",
    "                Q_sa = self.model.predict(state_t1)\n",
    "                \n",
    "                if state_t1 is None:\n",
    "                    targets[i,action_t] = reward_t\n",
    "                else:\n",
    "                    targets[i,action_t] = reward_t + GAMMA*np.max(Q_sa)\n",
    "                \n",
    "            \n",
    "            self.model.fit(inputs, targets ,batch_size= BATCH_SIZE, epochs=1, verbose=0)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as skimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOTAL_TrainTime = 100000\n",
    "\n",
    "IMGHEIGHT = 40\n",
    "IMGWIDTH = 40\n",
    "IMGHISTORY = 4\n",
    "\n",
    "def ProcessGameImage(RawImage):\n",
    "    \n",
    "    GreyImage = skimage.color.rgb2gray(RawImage)\n",
    "    \n",
    "    CroppedImage = GreyImage[0:400,0:400]\n",
    "    \n",
    "    ReducedImage = skimage.transform.resize(CroppedImage,(IMGHEIGHT,IMGWIDTH))\n",
    "    \n",
    "    ReducedImage = skimage.exposure.rescale_intensity(ReducedImage, out_range = (0,255))\n",
    "    \n",
    "    ReducedImage = ReducedImage / 128\n",
    "    \n",
    "    return ReducedImage\n",
    "        \n",
    "def TrainExperiment():\n",
    "    \n",
    "    TrainHistory = []\n",
    "    \n",
    "    TheGame = DCQL_Pong.PongGame()\n",
    "    \n",
    "    TheGame.InitialDisplay()\n",
    "    \n",
    "    TheAgent = DCQL_Agent.Agent()\n",
    "    \n",
    "    BestAction = 0\n",
    "    \n",
    "    [InitialScore, InitialScreenImage] = TheGame.PlayNextMove(BestAction)\n",
    "    InitialGameImage = ProcessGameImage(InitialScreenImage)\n",
    "    \n",
    "    GameState = np.stack((InitialGameImage,InitialGameImage,InitialGameImage,InitialGameImage),axis = 2)\n",
    "    \n",
    "    GameState = GameState.reshape(1, GameState.shape[0],GameState.shape[1],GameState.shape[2])\n",
    "    \n",
    "    \n",
    "    for i in range(TOTAL_TrainTime):\n",
    "        \n",
    "        BestAction = TheAgent.FindBestAct(GameState)\n",
    "        [ReturnScore, NewScreenImage] = TheGame.PlayNextMove(BestAction)\n",
    "        \n",
    "        NewGameImage = ProcessGameImage(NewScreenImage)\n",
    "        \n",
    "        NewGameImage = NewGameImage.reshape(1,NewGameImage.shape[0],NewGameImage.shape[1],1)\n",
    "        \n",
    "        NextState = np.append(NewGameImage, GameState[:,:,:,:3], axis = 3)\n",
    "        \n",
    "        TheAgent.CaptureSample((GameState,BestAction,ReturnScore,NextState))\n",
    "        \n",
    "        TheAgent.Process()\n",
    "        \n",
    "        GameState = NextState\n",
    "        \n",
    "        if i % 250 == 0:\n",
    "            print(\"Train time: \",i, \" game score: \",TheGame.GScore)\n",
    "            TrainHistory.append(TheGame.GScore)\n",
    "            \n",
    "        \n",
    "TrainExperiment()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
